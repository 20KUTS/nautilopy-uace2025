{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9b1160-19b4-4a09-8971-637b6ec77c45",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Presentation: Nautilopy applied to the 3D mapping of underwater caves\"\n",
    "subtitle: Overview of the work realized with Nautilopy on the underwater cave dataset\n",
    "authors:\n",
    "  - name: Thomas Guilment\n",
    "    affiliations:\n",
    "      - University of Louisiana at Lafayette\n",
    "    email: thomas.guilment@gmail.com\n",
    "    corresponding: true\n",
    "    orcid: 0009-0003-8163-3976\n",
    "  - name: Gabriele Morra\n",
    "    affiliations:\n",
    "      - University of Louisiana at Lafayette\n",
    "  - name: Leonardo Macelloni\n",
    "    affiliations:\n",
    "      - University of Mississippi\n",
    "  - name: Marco D'Emilio\n",
    "    affiliations:\n",
    "      - University of Southern University\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e26af5-ade5-4765-8593-f5c6530b494f",
   "metadata": {},
   "source": [
    "![](./img/Logo_nautilopy_tiny.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db7fe5-0441-4d43-b0fc-b571c41df824",
   "metadata": {},
   "source": [
    "(theUnderwaterCaveDataset)=\n",
    "## The underwater cave dataset\n",
    "NautiloPy already includes a `csv.zip` file in the data folder, which is used for the entire project.  \n",
    "The original data are available at [https://cirs.udg.edu/caves-dataset/](https://cirs.udg.edu/caves-dataset/). To access the corresponding article, see also [Maillos et al., 2017](doi:10.1177/0278364917732838)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1de71-7820-4bfe-9cb8-5bc5f6742500",
   "metadata": {},
   "source": [
    "### Abstract from the authors of the dataset\n",
    "\n",
    "From [Maillos et al., 2017](doi:10.1177/0278364917732838)\n",
    "\n",
    "\"We provide a data set collected with an autonomous underwater vehicle (AUV) tested in the unstructured environment of an underwater cave complex. The vehicle is equipped with two mechanically scanned imaging sonar (MSIS) to simultaneously map the caves' horizontal and vertical surfaces, a Doppler velocity log (DvL), two inertial measurement units (IMUs), a depth sensor, and a vertically mounted camera imaging the sea-floor for ground truth validation in specific points. Here we present data using this testbed that was collected while guided by a diver, due to the caves' spatial complexity, during July 2013. For ease of use, the original ROS bag files are accompanied by a derivative version combining imagery and human-readable text files for processing on other environments.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f932a2-5c9c-457f-b252-c7e2d3be3f72",
   "metadata": {},
   "source": [
    ":::{figure}\n",
    ":label: my-figure\n",
    ":align: left\n",
    "\n",
    "(aerial-view)=\n",
    "![The approximate path traveled underwater overlaid on an aerial image from Google Earth.](./img/CavesGoogleEarth2.jpg)\n",
    "\n",
    "(auv-config)=\n",
    "![AUV configuration](./img/auv_config.png)\n",
    "\n",
    "Aerial image showing the AUV trajectory and AUV configuration from [Maillos et al., 2017](doi:10.1177/0278364917732838).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55542859-8f37-4527-8eae-043235424ae9",
   "metadata": {},
   "source": [
    "::: {.callout-warning}\n",
    "#### Correction in Super Seaking Reference axis\n",
    "We believe that there is an error in the 3D axis representation of the vertical SONAR. The X-axis (in red) should point to the seafloor (not the sky). In this work, a 180° degrees rotation around the Z axis was applied.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f929583-8d90-4e21-981e-d3dcb919d7d1",
   "metadata": {},
   "source": [
    ":::{note} Dataset in details\n",
    ":class: dropdown\n",
    "%:header: Available data from sensors in CSV file\n",
    "- **/depth_sensor:** DS2806 HPS-A pressure sensor data.\n",
    "- **/dvl_linkquest:** LinkQuest NavQuest 600 sensor data. Contains bottom and water-referenced velocities and other important sensor data.\n",
    "- **/imu_adis:** Analog Devices ADIS16480 sensor data. Contains orientation as both Euler angles and quaternion. It also contains raw data for accelerometers, gyros, magnetometers, and temperature, and an estimation of the gyro biases.\n",
    "- **/imu_adis_ros:** Analog Devices ADIS16480 sensor orientation [using standard IMU ROS message.](http://wiki.ros.org/sensor_msgs)\n",
    "- **/imu_xsens_mti:** Xsens MTi sensor data. Same message type and the same information as the topic /imu_adis.\n",
    "- **/imu_xsens_mti_ros:** Xsens MTi sensor orientation using standard IMU ROS message.\n",
    "- **/odometry:** estimation of the robot pose provided as a [standard Odometry ROS message.](http://wiki.ros.org/nav_msgs)\n",
    "- **/sonar_micron:** Tritech Micron DST sensor beam data.\n",
    "- **/sonar_micron_ros:** Micron data provided as [standard Laserscan ROS message.](http://wiki.ros.org/sensor_msgs)\n",
    "- **/sonar_seaking:** Tritech Super SeaKing DFP profiler sensor beam data.\n",
    "- **/sonar_seaking_ros:** profiler data provided as standard Laserscan ROS message.\n",
    "- **/tf:** [standard ROS messages](http://wiki.ros.org/tf) containing sensor offsets.\n",
    "\n",
    "```{figure} ./img/sensors_offset.png\n",
    ":name: Sensors_offset\n",
    ":align: left\n",
    "Sensors offsets\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ff5b7-ca2a-45d8-92b8-58f40557dfb3",
   "metadata": {},
   "source": [
    "### Import Nautilopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82e6cd-41e1-4f0d-bca4-2b3f066ba5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilopy.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793dbf69-dc53-48f8-9aeb-52226c98c111",
   "metadata": {},
   "source": [
    "(prepareTheData)=\n",
    "## Prepare the data\n",
    "For completeness, instead of using the human format text file given by the dataset authors, the ROS bag data were extracted using the Python package `Bagpy` (see this [notebook](#ROS2csv) to see how it was done), and each topic was converted into CSV files. \n",
    "\n",
    "In this project, the odometry field is considered to be the best estimate of pose and orientation.\n",
    "Therefore, the pre-processing is about interpolating the odometry to fit the vertical and horizontal sonar data (same timestamps).\n",
    "\n",
    "Each processed data is saved as a pickle file.\n",
    "For more information, don't hesitate to check the `01_Preprocessing.ipynb` notebook by clicking the [link below](#01_Preprocessing). \n",
    "\n",
    ":::{warning} Correction\n",
    ":icon:False\n",
    "During the data pre-processing phase, the vertical sonar orientation 3D axis has proven to be wrong, which is why there is a correction at the end of this external notebook.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a486da4-901e-4a57-ab21-b4cff8c1c9ac",
   "metadata": {},
   "source": [
    "### Unzip the CSV dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc2fbd-b069-47c2-a558-5cf8a3df4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data are not unzip\n",
    "if not os.path.isdir(\"./data/csv/\"):\n",
    "    # Unizp the csv.zip file containing the CSV files\n",
    "    f_unzip_file(s_zip_path = os.path.join(\"data\", \"csv.zip\"), s_extract_path = os.path.join(\"data\", '.'))\n",
    "else:\n",
    "    print(\"\"\"The csv folder already exist.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95dd07-c464-43d6-930e-f216d9f1e45e",
   "metadata": {},
   "source": [
    "### Create the Pickle dataset from the CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0794e-76ba-4303-8308-348a5dde2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the pickle_dataset already exist\n",
    "if not os.path.isdir(\"./data/Pickle_dataset/\"):\n",
    "    %run 01_Preprocessing.ipynb\n",
    "else:\n",
    "    print(\"\"\"The folder Pickle_dataset already exists. \n",
    "If you want to recreate the Pickle dataset, delete the Pickle_dataset in the data folder, then re-run this cell.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31933af9-eff3-401a-a196-a1fbbb2d4ec4",
   "metadata": {},
   "source": [
    "### Load the pre-processed data\n",
    "A little trick is used to get the `globals()` (local variables in the workspace) from an outside function by passing the local `globals` variables from the current notebook. The pickle variables are loaded in the current notebook. This is like loading a common Matlab `workspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16044bfc-3c8c-48c7-9101-006553852232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the pickle files\n",
    "l_var = os.listdir(os.path.join('.','data','Pickle_dataset'))\n",
    "\n",
    "# Load only the needed variables\n",
    "glob = globals()\n",
    "f_load_var(os.path.join('.','data','Pickle_dataset'), glob, \n",
    "           ['m_xyz_pos', # XYZ AUV position\n",
    "            'm_ypr', # Yaw, Pitch, Roll associated with the AUV positions\n",
    "            'v_timestamp.pkl']) # Timestamps associated with AUV positions\n",
    "\n",
    "# Deleting glob\n",
    "del glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7174d5-45b5-4521-ae22-d5871cfddc98",
   "metadata": {
    "user_expressions": [
     {
      "expression": "m_xyz_pos.shape",
      "result": {
       "data": {
        "text/plain": "(21843, 3)"
       },
       "metadata": {},
       "status": "ok"
      }
     },
     {
      "expression": "m_ypr.shape",
      "result": {
       "data": {
        "text/plain": "(21843, 3)"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "(VisualizationOfTheAuvOrientationOverTheTrajectory)=\n",
    "## Visualization of the AUV orientation over the trajectory\n",
    "This part presents different solutions to visualize the AUV orientation over its trajectory.  \n",
    "We are using the variable `m_xyz_pos` {eval}`m_xyz_pos.shape` and `m_ypr` {eval}`m_ypr.shape` created from the `odometry` data to display the trajectory and orientation of the AUV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8846239-ea75-45ec-8609-f6b28ea6fbd0",
   "metadata": {},
   "source": [
    "### Traditional multi-view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0b7b9-ed79-42a7-84ae-a0efc498a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline mode that displays static images inside the notebook\n",
    "%matplotlib inline\n",
    "d_start = 9000      # Starting point (from 0 to np.shape(m_xyz_pos)[0])\n",
    "d_end = 11000       # Ending point (maximum value is np.shape(m_xyz_pos)[0])\n",
    "d_downsampling = 20 # For faster display, only shows 1 point every 20 points\n",
    "d_step = 300        # (default 200) Show the pose every 300 divided by downsampled points\n",
    "d_scale = 1.5       # (default 1.5) Length of the AUV 3D axis \n",
    "d_max_ticks = 8     # (default 5) number of ticks per axis\n",
    "\n",
    "f_plot_auv_orientation_subplots(\n",
    "    m_xyz_pos[d_start:d_end:d_downsampling], # XYZ AUV position\n",
    "    m_ypr[d_start:d_end:d_downsampling], # Yaw, Pitch, Roll associated with the AUV positions\n",
    "    d_step=int(d_step/d_downsampling), # updated step depending of downsampling\n",
    "    d_scale = d_scale, \n",
    "    d_max_ticks = d_max_ticks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997867c-341a-431b-aa4c-63f44c47758a",
   "metadata": {},
   "source": [
    "## Interactive AUV orientation over trajectory\n",
    "This section presents two interactive plots of the Autonomous 3D orientation axis over its trajectory.\n",
    "First, we use `Matplotlib`, then `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51911052-8952-4395-9bb4-47aa2bd1eb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6906dac-d431-47c6-878f-0ebc5f0289b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start = 0\n",
    "d_end = np.shape(m_xyz_pos)[0]\n",
    "d_downsampling = 10 # For faster and lighter display, only shows 1 point every 10 points\n",
    "d_step = 400 # (default 200) Show the pose every 400 divided by downsampled points\n",
    "d_scale = 3 # (default 1.5) Length of the AUV 3D axis \n",
    "d_max_ticks = 8 # (default 5) number of ticks per axis\n",
    "\n",
    "v_figsize =(12, 5) # (default (12,5)) Width size and height size of the main figure\n",
    "\n",
    "o_anim_auv_orientation = f_create_auv_orientation_animation(\n",
    "    m_xyz_pos[d_start:d_end:d_downsampling],\n",
    "    m_ypr[d_start:d_end:d_downsampling],\n",
    "    d_step=int(d_step/d_downsampling),\n",
    "    d_scale = d_scale,\n",
    "    d_max_ticks = d_max_ticks,\n",
    "    v_figsize = v_figsize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8669b7-ed48-427b-a0e4-d6ac11e722dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the animation into javascript then HTML in one line code\n",
    "display(HTML(o_anim_auv_orientation.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d76073-f984-442b-8b9e-3ce10c0faa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure to be back to the inline backend\n",
    "%matplotlib inline\n",
    "\n",
    "# Clean widgets in memory\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754a3dc-08e7-4e11-bc76-0d7c1dca39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the renderers \"plotly_mimetype\", \"Jupyterlab\", and \"notebook\" to ensure compatibility for the display animations\n",
    "# available renderers at https://plot.ly/python/renderers/\n",
    "import plotly.io as pio\n",
    "\n",
    "# Use Jupyterlab compatible renderers\n",
    "pio.renderers.default = \"jupyterlab+notebook+plotly_mimetype\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651e427-decc-449e-b748-c31ca8a647e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## User-defined parameters\n",
    "d_start = 0\n",
    "d_end = np.shape(m_xyz_pos)[0]\n",
    "d_downsampling = 10\n",
    "d_step = 200\n",
    "d_max_ticks = 5\n",
    "\n",
    "#d_step=int(d_step/d_downsampling)\n",
    "\n",
    "# Apply slicing and downsampling\n",
    "m_pos_sub = m_xyz_pos[d_start:d_end:d_downsampling].copy()\n",
    "m_ypr_sub = m_ypr[d_start:d_end:d_downsampling].copy()\n",
    "v_timestamp_sub = v_timestamp[d_start:d_end:d_downsampling].copy()\n",
    "\n",
    "fig = f_create_auv_orientation_animation_plotly(m_pos_sub, m_ypr_sub, v_timestamp_sub,int(d_step/d_downsampling))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ba42d-aeec-488a-8d68-dd40a5f36e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline backend and no widgets are still \"running\"\n",
    "plt.close('all')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecd631-5cf9-47c6-be10-a71ec5ddfd18",
   "metadata": {},
   "source": [
    "(VerticalAndHorizontalSonarDataVisualization)=\n",
    "## Vertical and horizontal SONAR data visualization\n",
    "\n",
    "This section presents different views of the sonar data:\n",
    "- Static Polar view: received energy per angle\n",
    "- Animated Polar view: received energy per range over time\n",
    "- Sonar as an image of received energy per range over time\n",
    "- Full view of sonar date with AUV trajectory path\n",
    "\n",
    "<!-- The received signals can be seen over time as an image. Each waveform can be plotted as curves. The Y axis from top to bottom represents the distance from which the energy is received. The X axis is the time. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb4de4-d8b9-475e-abc7-74f5c33f8b58",
   "metadata": {},
   "source": [
    "### Load the pre-processed sonar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beceb492-9b80-4962-9e5b-0596b7fec948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the needed variables\n",
    "glob = globals()\n",
    "f_load_var (os.path.join('.','data','Pickle_dataset'), glob,\n",
    "            ['m_beam_data_micron',       # (397, 45587) Received sonar data per range (397 bins from 0 to 20 meters) over time (associated with scanning angles) in dB\n",
    "             'v_angles_rad_micron',      # associated scanning angle over time in radian\n",
    "             'v_range_micron',           # Range scale from 0 to 20 over 397 bins\n",
    "             'm_beam_data_micron_clean', # Cleaned sonar data\n",
    "             'm_xyz_pos_micron',         # XYZ 3D position of the horizontal Micron sonar\n",
    "             'v_timestamp_micron',\n",
    "             'm_ypr_micron'])      # Timestamp associated with each sonar position\n",
    "del glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a9b73-503b-4748-9108-78150286f85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60611427-3e76-4214-9e85-ebd0df2b3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting when the sonar is 0º equivalent to the index 194 for the horizontal sonar\n",
    "d_start_micron = 194\n",
    "\n",
    "v_figsize = (8,8)\n",
    "\n",
    "# Observing 1 period (200 points)\n",
    "d_end_micron = d_start_micron + 200\n",
    "m_sonar = m_beam_data_micron[:,d_start_micron:d_end_micron]\n",
    "v_angle = v_angles_rad_micron[d_start_micron:d_end_micron]\n",
    "f_plot_polar_sonar_micron(m_sonar, v_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba411ed-b81f-4a9b-b383-449091491d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 200\n",
    "d_start_micron = 194\n",
    "d_end_micron = d_start_micron + d_image_width\n",
    "m_sonar_micron = m_beam_data_micron[:, d_start_micron:d_end_micron]\n",
    "v_angles_rad = v_angles_rad_micron\n",
    "\n",
    "v_figsize = (12,6)\n",
    "\n",
    "f_plot_horizontal_sonar_with_angles(m_sonar_micron, v_angles_rad, d_start_micron, d_image_width, v_range_micron, v_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb689e0-6a46-4abf-bc67-8c4caf303e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e27caa-52a1-4fb1-96ed-c71dc1cb57ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5022f-4f94-485b-8ca7-8655583d78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the needed variables\n",
    "glob = globals()\n",
    "f_load_var (os.path.join('.','data','Pickle_dataset'), glob, \n",
    "            ['m_beam_data_seaking', \n",
    "             'v_angles_rad_seaking',\n",
    "             'v_range_seaking',\n",
    "             'm_xyz_pos_seaking',\n",
    "             'v_timestamp_seaking',\n",
    "             'm_beam_data_seaking_clean'])\n",
    "del glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71648b63-24cb-4c35-9d79-37d6333c4be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a285f34-dd21-4ee5-ba4d-644807e23f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting when the sonar is 0º equivalent to the index 95 for the vertical sonar\n",
    "d_start_seaking = 95\n",
    "\n",
    "# Observing 1 period (201 points)\n",
    "d_end_seaking = d_start_seaking + 201\n",
    "\n",
    "# Figure size\n",
    "v_figsize = (8,8)\n",
    "\n",
    "# Extracting the wanted part\n",
    "m_sonar = m_beam_data_seaking[:,d_start_seaking:d_end_seaking]\n",
    "v_angle = v_angles_rad_seaking[d_start_seaking:d_end_seaking]\n",
    "f_plot_polar_sonar_seaking(m_sonar, v_angle, v_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96de6d-fdad-4459-aa41-a3467983ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 202 # 1 period of 201 index + 1 point to display the full 360º\n",
    "\n",
    "# Starting when the sonar is 0º equivalent to the index 95 for the vertical sonar\n",
    "d_start_seaking = 95 \n",
    "d_end_seaking = d_start_seaking + d_image_width\n",
    "\n",
    "m_sonar_seaking = m_beam_data_seaking[:, d_start_seaking:d_end_seaking]\n",
    "v_angles_rad = v_angles_rad_seaking\n",
    "f_plot_vertical_sonar_with_angles(m_sonar_seaking, v_angles_rad, d_start_seaking, d_image_width, v_range_seaking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472c5c6-6fb6-4443-adf7-7f8de954f13a",
   "metadata": {},
   "source": [
    "### Observing several sonar revolution\n",
    "> description..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fee609-b280-4147-b624-fd233ff7beac",
   "metadata": {},
   "source": [
    "### At the beginning of the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328323f-25d9-4ef3-9709-16030c469cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9bfaf-c112-4fbd-8ba3-fa7700278f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 1000\n",
    "d_start_micron = 1794\n",
    "# d_end_micron = d_start_micron + d_image_width\n",
    "m_sonar_micron = m_beam_data_micron[:, d_start_micron:d_start_micron+d_image_width]\n",
    "v_figsize = (16,6)\n",
    "f_plot_horizontal_sonar(m_sonar_micron, d_start_micron, d_image_width, v_range_micron, v_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07229a0e-e415-4781-b289-09ad1b44e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 800\n",
    "d_start_micron = 194 # Angle is 0 rad at index 194 and period every 200\n",
    "\n",
    "d_end_micron = d_start_micron + d_image_width\n",
    "\n",
    "# Put the seaking start accordingly to the micron for consistency\n",
    "d_start_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_start_micron]))\n",
    "d_end_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_end_micron]))\n",
    "\n",
    "d_image_width = d_end_seaking - d_start_seaking + 1\n",
    "\n",
    "# d_start_seaking = 95\n",
    "# d_end_seaking = d_start_seaking + d_image_width\n",
    "m_sonar_seaking = m_beam_data_seaking[:, d_start_seaking:d_start_seaking+d_image_width]\n",
    "v_figsize = (16,6)\n",
    "f_plot_vertical_sonar(m_sonar_seaking, d_start_seaking, d_image_width, v_range_seaking, v_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372367d-ff62-497b-bb29-ccb96aab0e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca7c22-db07-4dc0-bb79-e0ec090cc431",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 1400\n",
    "d_start_seaking = 95\n",
    "# d_end_seaking = d_start_seaking + d_image_width\n",
    "m_sonar_seaking = m_beam_data_seaking[:, d_start_seaking:d_start_seaking+d_image_width]\n",
    "v_figsize = (16,6)\n",
    "f_plot_vertical_sonar(m_sonar_seaking, d_start_seaking, d_image_width, v_range_seaking, v_figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98147f51-3183-4977-9b6c-10102eccd160",
   "metadata": {},
   "source": [
    "### In the middle of the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc50a9e9-7b38-481b-9371-8cde9fd1049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 800\n",
    "d_start_micron = 194 + 22400  # Angle is 0 rad at index 194 and period every 200\n",
    "# d_end_micron = d_start_micron + d_image_width\n",
    "m_sonar_micron = m_beam_data_micron[:, d_start_micron:d_start_micron+d_image_width]\n",
    "v_figsize = (16,6)\n",
    "f_plot_horizontal_sonar(m_sonar_micron, d_start_micron, d_image_width, v_range_micron, v_figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e87e1-2a72-4800-9d91-95974cac3878",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start_micron = 194 + 22400  # Angle is 0 rad at index 194 and period every 200\n",
    "d_end_micron = d_start_micron + 1400\n",
    "m_sonar_micron = m_beam_data_micron[:, d_start_micron:d_end_micron]\n",
    "f_plot_horizontal_sonar(m_sonar_micron, d_start_micron, d_image_width, v_range_micron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b1305-9197-405a-976a-4c40514fdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_image_width = 800\n",
    "d_start_micron = 194 + 22400 # Angle is 0 rad at index 194 and period every 200\n",
    "\n",
    "d_end_micron = d_start_micron + d_image_width\n",
    "\n",
    "# Put the seaking start accordingly to the micron for consistency\n",
    "d_start_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_start_micron]))\n",
    "d_end_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_end_micron]))\n",
    "\n",
    "d_image_width = d_end_seaking - d_start_seaking + 1\n",
    "\n",
    "# d_start_seaking = 95\n",
    "# d_end_seaking = d_start_seaking + d_image_width\n",
    "m_sonar_seaking = m_beam_data_seaking[:, d_start_seaking:d_start_seaking+d_image_width]\n",
    "v_figsize = (16,6)\n",
    "f_plot_vertical_sonar(m_sonar_seaking, d_start_seaking, d_image_width, v_range_seaking, v_figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5a562-61a7-4d2e-91bc-5b9cb82af53e",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "> Work in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca51507-707e-49c7-b8dc-f6b2f3397deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "ax[0].set_title(\"Horizontal Sonar back AUV body frame detection\")\n",
    "#ax[0].imshow(m_beam_data_micron[0:70, 594-35:594+35]) # 4159:4229])\n",
    "\n",
    "# Determine image extent in terms of the date numbers on the x-axis\n",
    "extent = [\n",
    "    0,            # x_min\n",
    "    70,           # x_max\n",
    "    v_range_micron[-1],           # y_max\n",
    "    v_range_micron[0]             # y_min (so 0m is at the top)\n",
    "]\n",
    "\n",
    "# Plot using imshow\n",
    "h_im = ax[0].imshow(\n",
    "    m_beam_data_micron[0:70, 594-35:594+35],\n",
    "    aspect='auto',\n",
    "    interpolation='none',\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# Measured values\n",
    "d_length_back_start = -35\n",
    "d_length_back_end = 35\n",
    "d_length_back_beam = 70\n",
    "\n",
    "d_start_micron = 22994\n",
    "\n",
    "ax[1].set_title(\"Horizontal Sonar back AUV body frame detection\")\n",
    "ax[1].imshow(m_beam_data_micron[0:70, d_start_micron - 35 : d_start_micron + 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984daf4-4ea8-49ec-8aad-4a7be5d18101",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "ax[0].set_title(\"Horizontal Sonar Front AUV Body Frame Detection\")\n",
    "ax[0].imshow(m_beam_data_micron[0:20, 4064:4133])\n",
    "\n",
    "# Measured values\n",
    "d_length_front_start = -35\n",
    "d_length_front_end = 35\n",
    "d_length_front_beam = 30\n",
    "\n",
    "d_start_micron = 22994 + 100\n",
    "\n",
    "ax[1].set_title(\"Horizontal Sonar Back AUV Body Frame Detection\")\n",
    "ax[1].imshow(m_beam_data_micron[0:20, d_start_micron - 35 : d_start_micron + 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ea4f2-53c4-49ab-890c-9b4f3089726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "ax[0].set_title(\"Horizontal Sonar back AUV body frame detection\")\n",
    "ax[0].imshow(\n",
    "    m_beam_data_micron[\n",
    "        0:d_length_back_beam, 1794 + d_length_back_start : 1794 + d_length_back_end #594 + d_length_back_start : 594 + d_length_back_end\n",
    "    ]\n",
    ")\n",
    "\n",
    "#1794\n",
    "\n",
    "ax[1].set_title(\"Horizontal Sonar front AUV body frame detection\")\n",
    "ax[1].imshow(\n",
    "    m_beam_data_micron[\n",
    "        0:d_length_front_beam, 1894 + d_length_front_start : 1894 + d_length_front_end #4099 + d_length_front_start : 4099 + d_length_front_end\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a0b8e-a48e-4449-b01f-222dc62a0463",
   "metadata": {},
   "source": [
    "### Interactive analysis\n",
    "Widget to update the part of the trajectory in color associated with the sonar image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8c62e-fa06-4de4-b92a-08739bb8c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5e918-8cfb-485b-8c31-14b5847a817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_micron_with_trajectory(m_xyz_pos_micron, m_beam_data_micron, v_range_micron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555cc3a-047d-46f4-9fae-9ae674818f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_seaking_with_trajectory(m_xyz_pos_seaking, m_beam_data_seaking, v_range_seaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a999f-fbb5-4ec3-8883-26e934b6e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the needed variables\n",
    "glob = globals()\n",
    "f_load_var (os.path.join('.','data','Pickle_dataset'), glob, \n",
    "            ['m_beam_data_seaking', \n",
    "             'v_angles_rad_seaking',\n",
    "             'v_range_seaking',\n",
    "             'm_xyz_pos_seaking',\n",
    "             'm_ypr_seaking',\n",
    "             'v_timestamp_seaking',\n",
    "             'm_beam_data_seaking_clean'])\n",
    "del glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e83a4-84f8-4ac1-91f7-9ee605243ba3",
   "metadata": {},
   "source": [
    "## Animation scanning sonar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a3885-6f28-472e-ac0b-0f4277a1df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = fig.add_subplot(projection=\"3d\", proj_type=\"ortho\")\n",
    "\n",
    "# Put the axis in color and names them (X,Y,Z)\n",
    "colors = (\"#FF6666\", \"#005533\", \"#1199EE\")  # Colorblind-safe RGB\n",
    "\n",
    "for i, (axis, c) in enumerate(zip((ax.xaxis, ax.yaxis, ax.zaxis),\n",
    "                                  colors)):\n",
    "    axlabel = axis.axis_name\n",
    "    axis.set_label_text(axlabel)\n",
    "    axis.label.set_color(c)\n",
    "    axis.line.set_color(c)\n",
    "    axis.set_tick_params(colors=c)\n",
    "\n",
    "d_start_seaking = 32456\n",
    "d_end_seaking = d_start_seaking + 2000\n",
    "\n",
    "# Plot trajectory with beginning and end\n",
    "m_pos_seaking = m_xyz_pos_seaking[d_start_seaking:d_end_seaking,:].copy()\n",
    "m_pos_seaking[:,2] = -m_pos_seaking[:,2]\n",
    "\n",
    "trajectory = m_pos_seaking.copy()\n",
    "\n",
    "# Setting the axes properties\n",
    "d_margin = 15\n",
    "ax.set_xlim3d([np.min(trajectory[:,0])-d_margin, np.max(trajectory[:,0])+d_margin])\n",
    "ax.set_xlabel('X')\n",
    "\n",
    "ax.set_ylim3d([np.min(trajectory[:,1])-d_margin, np.max(trajectory[:,1])+d_margin])\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "ax.set_zlim3d([np.min(trajectory[:,2])-d_margin, np.max(trajectory[:,2])+d_margin])\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "f_plot_3d_trajectory(ax,m_pos_seaking)\n",
    "ax.set_title(\"(y,z) view vertical sonar scanning (Starting at 0°)\")\n",
    "\n",
    "m_aux_pc_seaking,l_intensity_seaking = f_pointCloud(\n",
    "        m_xyz_pos_seaking[d_start_seaking:d_end_seaking,:], \n",
    "        m_ypr_seaking[d_start_seaking:d_end_seaking,:], \n",
    "        m_beam_data_seaking_clean[:,d_start_seaking:d_end_seaking], \n",
    "        v_angles_rad_seaking[d_start_seaking:d_end_seaking], \n",
    "        d_max_range=10, \n",
    "        d_thresh=0,b_return_intensity=True)\n",
    "\n",
    "seaking_color = np.concatenate(l_intensity_seaking)\n",
    "\n",
    "global p_pos\n",
    "global graph\n",
    "d_ind=0\n",
    "p_pos = ax.scatter(m_pos_seaking[d_ind,0],m_pos_seaking[d_ind,1],m_pos_seaking[d_ind,2],color='blue')\n",
    "#grap, = ax.plot(m_aux_pc_seaking[:,0], m_aux_pc_seaking[:,1], m_aux_pc_seaking[:,2], linestyle=\"\",marker=\"o\")\n",
    "\n",
    "# ax.legend()\n",
    "ax.view_init(20,65)\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "graph = ax.scatter(m_aux_pc_seaking[:,0], m_aux_pc_seaking[:,1], m_aux_pc_seaking[:,2], s=1, c=seaking_color, cmap='jet')\n",
    "\n",
    "\n",
    "l_index_seaking = [len(v_elem) for v_elem in l_intensity_seaking]\n",
    "l_index_seaking = np.concatenate(([0],np.cumsum(l_index_seaking)))\n",
    "\n",
    "\n",
    "#p = ax.scatter(m_aux_pc_seaking[:,0], m_aux_pc_seaking[:,1], m_aux_pc_seaking[:,2], s=1, c=seaking_color, cmap='jet')\n",
    "\n",
    "def f_update_anim_sonar(d_ind):\n",
    "    \n",
    "    global graph\n",
    "    global p_pos\n",
    "    graph.remove()\n",
    "    p_pos.remove()\n",
    "    # Create the plot and get the graph object\n",
    "    graph = ax.scatter(m_aux_pc_seaking[:l_index_seaking[d_ind],0], m_aux_pc_seaking[:l_index_seaking[d_ind],1], m_aux_pc_seaking[:l_index_seaking[d_ind],2], s=1, c=seaking_color[:l_index_seaking[d_ind]], cmap='jet')\n",
    "    p_pos = ax.scatter(m_pos_seaking[d_ind,0],m_pos_seaking[d_ind,1],m_pos_seaking[d_ind,2],color='yellow')\n",
    "    # Remove the previous plot and current plot\n",
    "    # graph.set_visible(False)\n",
    "\n",
    "    # Plot the new plot\n",
    "    # graph = ax.scatter(m_aux_pc_seaking[:d_ind,0], m_aux_pc_seaking[:d_ind,1], m_aux_pc_seaking[:d_ind,2], s=1, c=seaking_color[:d_ind], cmap='jet')\n",
    "    #graph._offsets3d = (m_aux_pc_seaking[d_ind:,0], m_aux_pc_seaking[d_ind:,1], m_aux_pc_seaking[d_ind:,2])\n",
    "    \n",
    "    #p = ax.scatter(m_aux_pc_seaking[:,0], m_aux_pc_seaking[:,1], m_aux_pc_seaking[:,2], s=1, c=seaking_color, cmap='jet')\n",
    "    fig.canvas.flush_events()\n",
    "    fig.canvas.draw_idle()\n",
    "    fig.canvas.draw()\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a39d2-bde3-4c57-8ad2-0cdfd81b1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_seaking_3D = interactive(\n",
    "    f_update_anim_sonar,\n",
    "    d_ind=widgets.IntSlider(min=1,max=d_end_seaking-d_start_seaking-1,step=1,value=10)) # widgets.FloatSlider(min=0,max=1,step=0.05,value=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b1c76-ddf5-458b-91f3-ef8c1587e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widget_seaking_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7512146-1a2b-41ad-832a-a223d514bd4c",
   "metadata": {},
   "source": [
    "## Cleaning the SONAR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ac686-1cf2-4d7f-b833-f349e7400ffd",
   "metadata": {},
   "source": [
    "#### Mask creation from intensity\n",
    "When the wall detection is close by, removing the body frame detection with a simple rectangle could also remove the detected wall.\n",
    "The idea is to create a mask of the body frame detection with intensity and subtract this intensity from the total data.\n",
    "In the case of font body detection, the wall detection doesn't seem to overlap the AUV body frame detection so a simple replacement of values should suffice.  \n",
    "\n",
    "Let's find a spot where the detected walls are very far to isolate only the body frame detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691d800-72ce-43ac-a0a1-53e1f42614f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mask_instensity_back = m_beam_data_micron[0:70, 594 - 35 : 594 + 35].copy()\n",
    "d_length_back_beam = 70\n",
    "d_length_back_start = -35\n",
    "d_length_back_end = 35\n",
    "\n",
    "m_mask_intensity_front = m_beam_data_micron[0:30, 4064:4134].copy()\n",
    "d_length_front_start = -35\n",
    "d_length_front_end = 35\n",
    "d_length_front_beam = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d59870-cb35-43aa-a97c-28883c8deb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "ax[0].set_title(\"Horizontal Sonar back AUV body frame detection\")\n",
    "ax[0].imshow(m_beam_data_micron[0:d_length_back_beam, 594 + d_length_back_start : 594 + d_length_back_end])\n",
    "\n",
    "ax[1].set_title(\"Horizontal Sonar front AUV body frame detection\")\n",
    "ax[1].imshow(m_beam_data_micron[0:d_length_front_beam, 4099 + d_length_front_start : 4099 + d_length_front_end]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495503d-c040-44ac-ace0-567f9a015486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf236b-f204-40c3-a74a-509397a76815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "\n",
    "d_start_micron = 22994\n",
    "d_end_micron = d_start_micron + 1000 + 1 # + 1 that display the '1000'\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(16, 9))\n",
    "ax[0].set_title(\"Before cleaning\")\n",
    "ax[0].imshow(m_beam_data_micron[:, d_start_micron:d_end_micron])\n",
    "\n",
    "ax[1].set_title(\"After cleaning\")\n",
    "ax[1].imshow(m_beam_data_micron_clean[:, d_start_micron:d_end_micron]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555020d-606a-4fcc-90e8-783bb770e3ad",
   "metadata": {},
   "source": [
    "## 3D point cloud from combining both SONAR data with a uniform colormap based on cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ac404-96b0-4f7e-adfd-02ced59254aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the needed variables\n",
    "glob = globals()\n",
    "f_load_var (os.path.join('.','data','Pickle_dataset'), glob, ['v_timestamp_seaking', 'v_timestamp_micron','m_ypr_micron','m_ypr_seaking'])\n",
    "del glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666db79b-7ffd-425f-9e17-9d1c162d8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_start_micron = 0 \n",
    "d_end_micron =  d_start_micron + np.shape(m_beam_data_micron_clean)[1]-1 #6500\n",
    "\n",
    "# Put the seaking start accordingly to the micron one\n",
    "d_start_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_start_micron]))\n",
    "d_end_seaking = np.argmin(np.abs(v_timestamp_seaking - v_timestamp_micron[d_end_micron]))\n",
    "\n",
    "# The max values are selected when d_tresh = -1\n",
    "m_point_cloud_micron_max = f_pointCloud(\n",
    "    m_xyz_pos_micron[d_start_micron:d_end_micron,:], \n",
    "    m_ypr_micron[d_start_micron:d_end_micron,:], \n",
    "    m_beam_data_micron_clean[:,d_start_micron:d_end_micron], \n",
    "    v_angles_rad_micron[d_start_micron:d_end_micron], \n",
    "    d_max_range=20, \n",
    "    d_thresh=-1)\n",
    "\n",
    "m_point_cloud_seaking_max = f_pointCloud(\n",
    "    m_xyz_pos_seaking[d_start_seaking:d_end_seaking,:], \n",
    "    m_ypr_seaking[d_start_seaking:d_end_seaking,:], \n",
    "    m_beam_data_seaking_clean[:,d_start_seaking:d_end_seaking], \n",
    "    v_angles_rad_seaking[d_start_seaking:d_end_seaking], \n",
    "    d_max_range=10, \n",
    "    d_thresh=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b2bab-d50e-4f4f-ab4d-9af41bbec7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(25,12))\n",
    "ax = fig.add_subplot(projection=\"3d\", proj_type=\"ortho\",box_aspect=(5,4,2))\n",
    "\n",
    "# Put the axis in color and name them (X,Y,Z)\n",
    "colors = (\"#FF6666\", \"#005533\", \"#1199EE\")  # Colorblind-safe RGB\n",
    "for i, (axis, c) in enumerate(zip((ax.xaxis, ax.yaxis, ax.zaxis),\n",
    "                                  colors)):\n",
    "    axlabel = axis.axis_name\n",
    "    axis.set_label_text(axlabel)\n",
    "    axis.label.set_color(c)\n",
    "    axis.line.set_color(c)\n",
    "    axis.set_tick_params(colors=c)\n",
    "\n",
    "m_pos_micron = m_xyz_pos_micron[d_start_micron:d_end_micron,:].copy()\n",
    "m_pos_micron[:,2] = -m_pos_micron[:,2]\n",
    "\n",
    "m_pos_seaking = m_xyz_pos_seaking[d_start_seaking:d_end_seaking,:].copy()\n",
    "m_pos_seaking[:,2] = -m_pos_seaking[:,2]\n",
    "\n",
    "micron_color = m_point_cloud_micron_max[:,2 ] #np.concatenate(l_intensity_micron)\n",
    "seaking_color = m_point_cloud_seaking_max[:,2]\n",
    "\n",
    "# Put the same max and min value to have the same color map\n",
    "d_min = np.min((np.min(micron_color),np.min(seaking_color)))\n",
    "d_max = np.max((np.max(micron_color),np.max(seaking_color)))\n",
    "micron_color[micron_color == np.min(micron_color)] = d_min\n",
    "seaking_color[seaking_color == np.min(seaking_color)] = d_min\n",
    "\n",
    "micron_color[micron_color == np.max(micron_color)] = d_max\n",
    "seaking_color[seaking_color == np.max(seaking_color)] = d_max\n",
    "\n",
    "# Plot trajectory with beginning and end\n",
    "# f_plot_3d_trajectory(ax,m_pos_micron)\n",
    "f_plot_3d_trajectory(ax,m_pos_seaking)\n",
    "\n",
    "p = ax.scatter(m_point_cloud_micron_max[:,0], m_point_cloud_micron_max[:,1], m_point_cloud_micron_max[:,2], s=1, c=micron_color, cmap='jet', label='Micron')\n",
    "p = ax.scatter(m_point_cloud_seaking_max[:,0], m_point_cloud_seaking_max[:,1], m_point_cloud_seaking_max[:,2], s=1, c=seaking_color, cmap='jet', label='Seaking')\n",
    "\n",
    "ax.set_title(\"Perspective view map \")\n",
    "# ax.legend()\n",
    "ax.view_init(30,45)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_title(\"3D Point cloud from Horizontal and vertical SONAR\", fontsize=30)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.dist = 0\n",
    "fig.colorbar(p,shrink=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82b10a-5564-4e9e-ae29-b32fc12b0526",
   "metadata": {},
   "source": [
    "::::{note} Link to external notebooks\n",
    "(01_Preprocessing)=\n",
    ":::{card} 01_Preprocessing.ipynb\n",
    ":link: ./01_Preprocessing.ipynb\n",
    "See all the processes that have been done on the data from the CSV dataset to the pickle file\n",
    ":::\n",
    "\n",
    "(ROS2csv)=\n",
    ":::{card} ROSbag2csv.ipynb\n",
    ":link: ./ROSbag2csv.ipynb\n",
    "See how to extract ROS bag data and convert each topic to a CSV file.\n",
    ":::\n",
    "::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev-env",
   "language": "python",
   "name": "nbdev-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
