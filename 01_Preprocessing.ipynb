{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e15c35f-3bfe-4af9-9ff8-b7ae0b09c89b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Save workspace variables into Pickle files \"\n",
    "summary: \"This notebook shows the pre-processing steps before saving the global variables into either a one-file dataset or each variable in a folder using the `pickle` module.\"\n",
    "authors:\n",
    "  - name: Thomas Guilment\n",
    "    affiliations:\n",
    "      - University of Louisiana at Lafayette\n",
    "    email: thomas.guilment@gmail.com\n",
    "    corresponding: true\n",
    "    orcid: 0009-0003-8163-3976\n",
    "  - name: Gabriele Morra\n",
    "    affiliations:\n",
    "      - University of Louisiana at Lafayette\n",
    "  - name: Leonardo Macelloni\n",
    "    affiliations: University of Mississippi\n",
    "  - name: Marco D'Emidio\n",
    "    affiliations:\n",
    "      - University of Southern University\n",
    "format:\n",
    "  html:\n",
    "    page-layout: article\n",
    "    toc: true\n",
    "    toc-depth: 2\n",
    "    number-sections: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85818d66-a1ad-46b8-90c1-718af18e1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our module\n",
    "from nautilopy.core import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5884e765-d6d2-42d2-bc9b-b982e4cdabc4",
   "metadata": {},
   "source": [
    "![](./img/Logo_nautilopy_tiny.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42f043ab-875a-45b4-b890-7518d5a6d6a9",
   "metadata": {},
   "source": [
    "(theUnderwaterCaveDataset)=\n",
    "## The underwater cave dataset\n",
    "NautiloPy already includes a `csv.zip` file in the data folder, which is used for the entire project.  \n",
    "The original data are available at [https://cirs.udg.edu/caves-dataset/](https://cirs.udg.edu/caves-dataset/). To access the corresponding article, see also [Maillos et al., 2017](doi:10.1177/0278364917732838)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beb72556-fb3e-4760-bfda-40ab8b24d9d6",
   "metadata": {},
   "source": [
    ":::{note} Dataset in details...\n",
    ":class: dropdown\n",
    "%:header: Available data from sensors in CSV file\n",
    "- **/depth_sensor:** DS2806 HPS-A pressure sensor data.\n",
    "- **/dvl_linkquest:** LinkQuest NavQuest 600 sensor data. Contains bottom and water-referenced velocities and other important sensor data.\n",
    "- **/imu_adis:** Analog Devices ADIS16480 sensor data. It contains orientation in both Euler angles and quaternion. It also contains raw data for accelerometers, gyros, magnetometers, and temperature, and an estimation of the gyro biases.\n",
    "- **/imu_adis_ros:** Analog Devices ADIS16480 sensor orientation [using standard IMU ROS message.](http://wiki.ros.org/sensor_msgs)\n",
    "- **/imu_xsens_mti:** Xsens MTi sensor data. It has the same message type and the same information as the topic /imu_adis.\n",
    "- **/imu_xsens_mti_ros:** Xsens MTi sensor orientation using standard IMU ROS message.\n",
    "- **/odometry:** estimation of the robot pose provided as a [standard Odometry ROS message.](http://wiki.ros.org/nav_msgs)\n",
    "- **/sonar_micron:** Tritech Micron DST sensor beam data.\n",
    "- **/sonar_micron_ros:** Micron data provided as [standard Laserscan ROS message.](http://wiki.ros.org/sensor_msgs)\n",
    "- **/sonar_seaking:** Tritech Super SeaKing DFP profiler sensor beam data.\n",
    "- **/sonar_seaking_ros:** Profiler data was provided as a standard Laserscan ROS message.\n",
    "- **/tf:** [standard ROS messages](http://wiki.ros.org/tf) containing sensor offsets.\n",
    "\n",
    "```{figure} ./img/sensors_offset.png\n",
    ":name: Sensors_offset\n",
    ":align: left\n",
    "Sensors offsets\n",
    "```\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17d551f2-133d-4830-b614-8c6e105c34e0",
   "metadata": {},
   "source": [
    "# Overview of the pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cd42cdb-7e1c-4154-9167-c842e4228761",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "%%{init: {\n",
    "  'theme': 'base',\n",
    "  'themeVariables': {\n",
    "    'primaryColor': '#3498db',\n",
    "    'primaryTextColor': '#ffffff',\n",
    "    'primaryBorderColor': '#2980b9',\n",
    "    'lineColor': '#2980b9',\n",
    "    'secondaryColor': '#2ecc71',\n",
    "    'tertiaryColor': '#f1c40f'\n",
    "  },\n",
    "  'flowchart': {\n",
    "    'nodeSpacing': 50,\n",
    "    'rankSpacing': 20,\n",
    "    'padding': 15\n",
    "  }\n",
    "}}%%\n",
    "\n",
    "graph TB\n",
    "    %% Raw Data\n",
    "    A[(Raw Data)]\n",
    "\n",
    "    %% Main Processing Steps\n",
    "    subgraph DataProcessing [\"Data reading\"]\n",
    "        direction TB\n",
    "        B[\"Pose and<br/>Navigation\"]\n",
    "        C[\"Sonar<br/>Data\"]\n",
    "        D[\"Depth<br/>Sensor\"]\n",
    "        E[\"DVL<br/>Data\"]\n",
    "    end\n",
    "\n",
    "    %% Interpolation and Adjustment\n",
    "    subgraph DataIntegration [\"Data Integration & Alignment\"]\n",
    "        direction TB\n",
    "        F[\"Position & Euler<br/>Angles Interpolation\"]\n",
    "        G[\"Dimension<br/>Adjustment\"]\n",
    "        H[\"Seafloor Map<br/>Data Preparation\"]\n",
    "    end\n",
    "\n",
    "    %% Cleaning and Correction\n",
    "    subgraph DataCleaning [\"Data Cleaning & Correction\"]\n",
    "        direction TB\n",
    "        I[\"Vertical Sonar<br/>Orientation Correction\"]\n",
    "        J[\"Horizontal Sonar<br/>Noise Reduction\"]\n",
    "        K[\"Vertical Sonar<br/>Noise Reduction\"]\n",
    "    end\n",
    "\n",
    "    %% Additional Processing\n",
    "    L[\"Depth Profile<br/>Analysis\"]\n",
    "    M[\"Velocity & Altitude<br/>Processing\"]\n",
    "\n",
    "    %% Data Fusion & Optimization\n",
    "    N[\"Data Fusion &<br/>Optimization\"]\n",
    "\n",
    "    %% Data Outputs\n",
    "    subgraph DataOutputs [\"Processed Data Outputs in Pickle format\"]\n",
    "        direction TB\n",
    "        O[\"AUV Position &<br/>Orientation\"]\n",
    "        P[\"Sonar Intensity<br/>Data\"]\n",
    "        Q[\"Configuration<br/>Parameters\"]\n",
    "        R[\"Temporal<br/>Information\"]\n",
    "        S[\"Auxiliary<br/>Parameters\"]\n",
    "    end\n",
    "\n",
    "    %% Connections\n",
    "    A --> DataProcessing\n",
    "    DataProcessing --> DataIntegration\n",
    "    DataIntegration --> DataCleaning\n",
    "    DataProcessing --> L & M\n",
    "    DataCleaning --> N\n",
    "    L & M --> N\n",
    "    N --> DataOutputs\n",
    "\n",
    "    %% Styling\n",
    "    classDef default fill:#f0f0f0,stroke:#333,stroke-width:1px,font-family:Arial,font-size:12px\n",
    "    classDef process fill:#3498db,stroke:#2980b9,color:#fff,font-weight:bold\n",
    "    classDef data fill:#2ecc71,stroke:#27ae60,color:#fff,font-weight:bold\n",
    "    classDef cleaning fill:#2ecc71,stroke:#27ae60,color:#fff,font-weight:bold\n",
    "    classDef output fill:#f39c12,stroke:#d35400,color:#fff,font-weight:bold\n",
    "    classDef subgraphStyle fill:#ecf0f1,stroke:#95a5a6,color:#34495e,font-weight:bold,font-size:14px\n",
    "\n",
    "    class A data\n",
    "    class B,C,D,E,F,G,H,L,M,N process\n",
    "    class I,J,K cleaning\n",
    "    class O,P,Q,R,S output\n",
    "    class DataProcessing,DataIntegration,DataCleaning,DataOutputs subgraphStyle\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "916c2b66-7242-429c-9717-59033bce564c",
   "metadata": {},
   "source": [
    "### Check if the CSV data set has been unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974eecb-e180-46c7-bc4c-6e311096d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data are not unzip\n",
    "if not os.path.isdir(\"./data/csv/\"):\n",
    "    # Unizp the csv.zip file containing the CSV files\n",
    "    f_unzip_file(s_zip_path = os.path.join(\"data\", \"csv.zip\"), s_extract_path = os.path.join(\"data\", '.'))\n",
    "else:\n",
    "    print(\"\"\"The csv folder already exist.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858441f1-5ee9-4586-a44f-d306f0e78a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86848c78-8269-406a-b81a-322fc9d92c06",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3054c768-0b72-4eb9-8518-3b32ecd7e598",
   "metadata": {},
   "source": [
    "## Pose and Navigation data\n",
    "\n",
    "Processes pose and navigation data for an Autonomous Underwater Vehicle (AUV):\n",
    "1. Loads odometry data from a CSV file\n",
    "2. Extract 3D position of the AUV\n",
    "3. Extract quaternion orientation data\n",
    "4. Converts quaternions to Euler angles (Yaw, Pitch, Roll)\n",
    "\n",
    "The resulting data includes:  \n",
    "- `m_xyz_pos`: 3D XYZ AUV position matrix  \n",
    "- `m_quaternion`: Quaternion orientation matrix  \n",
    "- `m_ypr`: Matrix of Yaw, Pitch, and Roll angles in radian\n",
    "\n",
    ":::{.callout-note}\n",
    "\n",
    "The `odometry` data is used as the best navigation estimate.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788b11b-85ea-4f35-a4fc-7d40d96fbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder path\n",
    "s_data_folder_path = os.path.join('.', 'data', 'csv')\n",
    "\n",
    "# 3D position of the AUV\n",
    "df_odometry = pd.read_csv(os.path.join(s_data_folder_path,'odometry.csv'))\n",
    "m_xyz_pos = df_odometry[['pose.pose.position.x','pose.pose.position.y','pose.pose.position.z']].to_numpy(copy=True)\n",
    "\n",
    "# 3D orientation from the Quaternions \n",
    "df_quaternion_odometry = df_odometry[[\"pose.pose.orientation.x\",\"pose.pose.orientation.y\",\"pose.pose.orientation.z\",\"pose.pose.orientation.w\"]]\n",
    "m_quaternion = df_quaternion_odometry.to_numpy(copy=True)\n",
    "\n",
    "# Convert quaternion to Euler angles\n",
    "m_ypr = np.zeros((np.shape(m_quaternion)[0],3))\n",
    "for index, q in enumerate(m_quaternion):\n",
    "    roll, pitch, yaw = f_q2rollPitchYaw(q)\n",
    "    m_ypr[index,:] = np.array([yaw,pitch,roll])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f23538-8880-4f1f-9be2-2ae0ebd3cbce",
   "metadata": {},
   "source": [
    "### Position and Euler angles interpolation\n",
    "Processes and interpolates position and orientation data for two sonars (Micron and SeaKing) on an AUV:\n",
    "\n",
    "1. Loads data for both sonars and odometry  \n",
    "2. Extracts timestamps for navigation and both sonars  \n",
    "3. Interpolates 3D position data to match sonar timestamps  \n",
    "4. Applies position offsets to account for sonar placement on the AUV  \n",
    "5. Performs orientation interpolation using Slerp (Spherical Linear Interpolation)  \n",
    "6. Converts interpolated quaternions to Euler angles (Yaw, Pitch, Roll)  \n",
    "7. Applies orientation offsets for each sonar  \n",
    "\n",
    "```{figure} ./img/sensors_offset.png\n",
    ":name: Sensors_offset\n",
    ":align: left\n",
    "Sensors offsets\n",
    "```\n",
    "\n",
    "Key steps:  \n",
    "- Uses numpy's `interp` function for position interpolation  \n",
    "- Employs Scipy's `Slerp` for quaternion interpolation  \n",
    "- Handles timestamp mismatches by trimming sonar data to fit within navigation timestamps  \n",
    "- Converts quaternions to Euler angles using our `f_q2rollPitchYaw` function  \n",
    "\n",
    "Key outputs:  \n",
    "- `m_interp_pos_micron`, `m_interp_pos_seaking`: Interpolated 3D positions for each sonar  \n",
    "- `m_interp_micron_YPR`, `m_interp_seaking_YPR`: Interpolated and offset-corrected Euler angles for each sonar  \n",
    "- `v_offset_pos_micron`, `v_offset_pos_seaking`: Position offsets for each sonar  \n",
    "- `v_offset_ypr_micron`, `v_offset_ypr_seaking`: Orientation offsets for each sonar  \n",
    "\n",
    "This process ensures accurate alignment of sonar data with the AUV's position and orientation, accounting for the physical placement of sonars on the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa4fa6-a831-4ba5-a752-e6997745f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation of position for both sonars taking the offset into account\n",
    "# Load the vertical and horizontal mechanical sonars\n",
    "df_sonar_micron = pd.read_csv(os.path.join(s_data_folder_path, 'sonar_micron.csv'))\n",
    "df_sonar_seaking = pd.read_csv(os.path.join(s_data_folder_path, 'sonar_seaking.csv'))\n",
    "df_odometry = pd.read_csv(os.path.join(s_data_folder_path, 'odometry.csv'))\n",
    "\n",
    "# Extract timestamps\n",
    "v_timestamp = df_odometry[\"Time\"].to_numpy(copy=True)\n",
    "v_timestamp_sonar_micron = df_sonar_micron[\"Time\"].to_numpy(copy=True)\n",
    "v_timestamp_sonar_seaking = df_sonar_seaking[\"Time\"].to_numpy(copy=True)\n",
    "\n",
    "# 3D position of the AUV\n",
    "m_xyz_pos = df_odometry[['pose.pose.position.x','pose.pose.position.y','pose.pose.position.z']].to_numpy(copy=True)\n",
    "\n",
    "# Interpolate position to fit the SONAR timestamps dimension\n",
    "v_interp_micron_x = np.interp(v_timestamp_sonar_micron, v_timestamp, m_xyz_pos[:,0], left=None, right=None, period=None)\n",
    "v_interp_micron_y = np.interp(v_timestamp_sonar_micron, v_timestamp, m_xyz_pos[:,1], left=None, right=None, period=None)\n",
    "v_interp_micron_z = np.interp(v_timestamp_sonar_micron, v_timestamp, m_xyz_pos[:,2], left=None, right=None, period=None)\n",
    "\n",
    "v_interp_seaking_x = np.interp(v_timestamp_sonar_seaking, v_timestamp, m_xyz_pos[:,0], left=None, right=None, period=None)\n",
    "v_interp_seaking_y = np.interp(v_timestamp_sonar_seaking, v_timestamp, m_xyz_pos[:,1], left=None, right=None, period=None)\n",
    "v_interp_seaking_z = np.interp(v_timestamp_sonar_seaking, v_timestamp, m_xyz_pos[:,2], left=None, right=None, period=None)\n",
    "\n",
    "# Concatenate into a matrix\n",
    "m_interp_pos_micron = np.c_[v_interp_micron_x,v_interp_micron_y,v_interp_micron_z]\n",
    "m_interp_pos_seaking = np.c_[v_interp_seaking_x,v_interp_seaking_y,v_interp_seaking_z]\n",
    "\n",
    "# (dx, dy, dz) offsets from reference to consider in the 3D sonar position\n",
    "v_offset_pos_micron = np.array([0.1,0,-0.42])\n",
    "v_offset_pos_seaking = np.array([0.55,0,0.15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537001fe-e34e-4551-a12d-b419682e451d",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Simply adding the 3D cartesian offset would be incorrect as we need to consider the 3D pose and orientation of the AUV body to determine what is the real 3D offset of the sonars.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68923870-2012-4f32-b159-12c35addae69",
   "metadata": {},
   "source": [
    "In this part, we interpolate the orientation (from quaternions) of the sonars for each timestamps, then we will use this information to estimate the proper 3D offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8f723-893f-4936-afb1-152b041bc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation with Scipy\n",
    "r_ypr_odometry = R.from_quat(m_quaternion)\n",
    "\n",
    "# Slerp algorithm\n",
    "slerp = Slerp(v_timestamp,r_ypr_odometry)\n",
    "\n",
    "# Interpolate for the new timestamps\n",
    "\n",
    "# The timestamp of Micron and Seaking are bigger and this raises a ValueError as the interpolation becomes an extrapolation.\n",
    "# We decide to remove the beginning and end part of the survey from the sonar timestamps to fit inside the navigation timestamps.\n",
    "d_min_thresh = v_timestamp[0]\n",
    "d_max_thresh = v_timestamp[-1]\n",
    "\n",
    "d_ind_min_micron = sum(v_timestamp_sonar_micron < d_min_thresh)\n",
    "d_ind_max_micron = len(v_timestamp_sonar_micron) - sum(v_timestamp_sonar_micron > d_max_thresh)\n",
    "\n",
    "d_ind_min_seaking = sum(v_timestamp_sonar_seaking < d_min_thresh)\n",
    "d_ind_max_seaking = len(v_timestamp_sonar_seaking) -  sum(v_timestamp_sonar_seaking > d_max_thresh)\n",
    "\n",
    "r_interp_ypr_odometry_micron = slerp(v_timestamp_sonar_micron[d_ind_min_micron:d_ind_max_micron])\n",
    "r_interp_ypr_odometry_seaking = slerp(v_timestamp_sonar_seaking[d_ind_min_seaking:d_ind_max_seaking])\n",
    "\n",
    "# Initialize variables\n",
    "l_yaw_pitch_roll = []\n",
    "m_interp_micron_YPR = np.zeros((np.shape(r_interp_ypr_odometry_micron.as_quat())[0],3))\n",
    "m_interp_seaking_YPR = np.zeros((np.shape(r_interp_ypr_odometry_seaking.as_quat())[0],3))\n",
    "\n",
    "# Convert quaternion to Euler angles\n",
    "for index, q in enumerate(r_interp_ypr_odometry_micron.as_quat()):\n",
    "    roll, pitch, yaw = f_q2rollPitchYaw(q)\n",
    "    l_yaw_pitch_roll.append([yaw,pitch,roll])\n",
    "    m_interp_micron_YPR[index,:] = np.array([yaw,pitch,roll])\n",
    "\n",
    "for index, q in enumerate(r_interp_ypr_odometry_seaking.as_quat()):\n",
    "    roll, pitch, yaw = f_q2rollPitchYaw(q)\n",
    "    l_yaw_pitch_roll.append([yaw,pitch,roll])\n",
    "    m_interp_seaking_YPR[index,:] = np.array([yaw,pitch,roll])\n",
    "\n",
    "# (yaw, pitch, roll) offsets in radian\n",
    "v_offset_ypr_micron       = np.array([ np.pi, 0.0, 0.0 ])\n",
    "v_offset_ypr_seaking      = np.array([ np.pi, np.pi/2, 0.0 ])\n",
    "\n",
    "# Final Euler angle with offset compensation\n",
    "m_interp_micron_YPR -= v_offset_ypr_micron\n",
    "m_interp_seaking_YPR -= v_offset_ypr_seaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f6c69-4c19-4218-b642-452a8e686812",
   "metadata": {},
   "source": [
    "Now that we have interpolated the orientations, we can estimate the 3D offset for each timestamp (or sonar ping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44ede5-d53a-4119-a0e3-d7674f332f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the sonar offsets into world frame\n",
    "m_rotated_offset_micron = r_interp_ypr_odometry_micron.apply(v_offset_pos_micron)\n",
    "m_rotated_offset_seaking = r_interp_ypr_odometry_seaking.apply(v_offset_pos_seaking)\n",
    "\n",
    "# Trim interpolated AUV positions to match orientation data length\n",
    "m_interp_pos_micron_trimmed = m_interp_pos_micron[d_ind_min_micron:d_ind_max_micron]\n",
    "m_interp_pos_seaking_trimmed = m_interp_pos_seaking[d_ind_min_seaking:d_ind_max_seaking]\n",
    "\n",
    "# Final sonar positions = AUV position + rotated offset\n",
    "m_xyz_pos_micron = m_interp_pos_micron_trimmed + m_rotated_offset_micron\n",
    "m_xyz_pos_seaking = m_interp_pos_seaking_trimmed + m_rotated_offset_seaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747902fd-3d9d-42ba-ab87-645617f519a1",
   "metadata": {},
   "source": [
    ":::{note} Positive Depth values\n",
    "The depth values are positive.  \n",
    "We will change the z coordinates to -z for the visualization when needed.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b7932be-b5a4-4850-9665-afd9ce5559d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9d12e-eb53-4468-b755-0ab74d577307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The timestamp of Micron and Seaking are bigger and this raises a ValueError as the interpolation becomes an extrapolation.\n",
    "# # We decide to remove the beginning and end part of the survey from the sonar timestamps to fit inside the navigation timestamps.\n",
    "# d_min_thresh = v_timestamp[0]\n",
    "# d_max_thresh = v_timestamp[-1]\n",
    "\n",
    "# d_ind_min_micron = sum(v_timestamp_sonar_micron < d_min_thresh)\n",
    "# d_ind_max_micron = len(v_timestamp_sonar_micron) - sum(v_timestamp_sonar_micron > d_max_thresh)\n",
    "\n",
    "# d_ind_min_seaking = sum(v_timestamp_sonar_seaking < d_min_thresh)\n",
    "# d_ind_max_seaking = len(v_timestamp_sonar_seaking) -  sum(v_timestamp_sonar_seaking > d_max_thresh)\n",
    "# m_interp_pos_micron = m_p_sonar_micron.copy()\n",
    "# m_interp_pos_seaking = m_p_sonar_seaking.copy()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6063c0e1-f768-4f3a-ae6a-5f9c7a29d140",
   "metadata": {},
   "source": [
    "### Dimension adjustment\n",
    "Adjusts the dimensions of the sonar data to ensure consistency with the interpolated navigation data:  \n",
    "\n",
    "1. Trims the interpolated position data for both Micron and SeaKing sonars  \n",
    "2. Extracts beam data from the sonar DataFrames  \n",
    "3. Converts beam data to numpy arrays for efficient processing  \n",
    "4. Adjusts the dimensions of the sonar intensity data to match the trimmed navigation data  \n",
    "5. Trims the sonar timestamps to match the adjusted data  \n",
    "\n",
    "Key operations:  \n",
    "- Uses array slicing to trim data (`[d_ind_min:d_ind_max]`)  \n",
    "- Extracts beam data columns using list comprehension  \n",
    "- Transposes sonar intensity matrices for consistent orientation  \n",
    "\n",
    "Key outputs:  \n",
    "- `m_interp_pos_micron_final`, `m_interp_pos_seaking_final`: Trimmed interpolated positions  \n",
    "- `m_beam_data_micron_final`, `m_beam_data_seaking_final`: Adjusted sonar intensity data  \n",
    "- `v_timestamp_sonar_micron_final`, `v_timestamp_sonar_seaking_final`: Trimmed sonar timestamps  \n",
    "\n",
    "This dimension adjustment ensures that all data arrays (position, orientation, intensity, and timestamps) are aligned and have consistent sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e91eaf-9c90-442e-abf1-5bd336c5f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position\n",
    "m_interp_pos_micron_final = m_interp_pos_micron[d_ind_min_micron:d_ind_max_micron,:].copy()\n",
    "m_interp_pos_seaking_final = m_interp_pos_seaking[d_ind_min_seaking:d_ind_max_seaking,:].copy()\n",
    "\n",
    "# Extract the beam data\n",
    "df_beam_data_micron = df_sonar_micron[[col for col in df_sonar_micron.columns if col.startswith('beam_data')]].copy()\n",
    "df_beam_data_seaking = df_sonar_seaking[[col for col in df_sonar_seaking.columns if col.startswith('beam_data')]].copy()\n",
    "\n",
    "# Conversion to numpy ndarray\n",
    "m_beam_data_micron = df_beam_data_micron.to_numpy(copy=True)\n",
    "m_beam_data_seaking = df_beam_data_seaking.to_numpy(copy=True)\n",
    "\n",
    "# Dimension adjustment\n",
    "m_beam_data_micron_final = m_beam_data_micron[d_ind_min_micron:d_ind_max_micron,:].copy().T\n",
    "m_beam_data_seaking_final = m_beam_data_seaking[d_ind_min_seaking:d_ind_max_seaking,:].copy().T\n",
    "\n",
    "v_timestamp_sonar_micron_final = v_timestamp_sonar_micron[d_ind_min_micron:d_ind_max_micron]\n",
    "v_timestamp_sonar_seaking_final = v_timestamp_sonar_seaking[d_ind_min_seaking:d_ind_max_seaking]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "468128d9-f20f-4f78-9e7e-370e3182cf57",
   "metadata": {},
   "source": [
    "### Additional data for seafloor map creation\n",
    "Prepares additional data necessary for creating a seafloor map from sonar readings:\n",
    "\n",
    "1. Defines range vectors for both Micron and SeaKing sonars\n",
    "2. Extracts scanning angles from sonar data\n",
    "3. Adjusts dimensions of angle data to match previously trimmed datasets\n",
    "\n",
    "Key points:  \n",
    "- Range vectors are created using `np.linspace`:  \n",
    "  - Micron sonar: 0 to 19.9496231079101 meters (397 points)  \n",
    "  - SeaKing sonar: 0 to 9.80000019073486 meters (50 points)  \n",
    "- Scanning angles are extracted in radians  \n",
    "- Dimensions of angle data are adjusted to match previously trimmed datasets  \n",
    "\n",
    "Key outputs:  \n",
    "- `v_range_micron`, `v_range_seaking`: Range vectors for each sonar  \n",
    "- `v_angles_rad_micron_final`, `v_angles_rad_seaking_final`: Trimmed scanning angle data  \n",
    "\n",
    "\n",
    "::: {.callout-warning}\n",
    "#### Note: There's a discrepancy between the article's stated ranges and the actual data ranges  \n",
    "- Micron: Article states 50 meters, data shows 19.9496231079101 meters (found in `sonar_micron_ros.csv`)\n",
    "- SeaKing: Article states 20 meters, data shows 9.80000019073486 meters (found in `sonar_seaking_ros.csv`)\n",
    "\n",
    "See **2.2. Perception sensors** part of [Maillos et al., 2017](doi:10.1177/0278364917732838)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99159ac5-fb4f-4e93-acd8-0b77f89e4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated range per beam in meter\n",
    "# Convert energy per distance into an estimated range\n",
    "# Attention, the article says 50 meters and the data says 19.5 meters\n",
    "v_range_micron = np.linspace(0,19.9496231079101,397)\n",
    "\n",
    "# Same, the article says 20 when the data shows 9.8 meters\n",
    "v_range_seaking = np.linspace(0,9.80000019073486,50)\n",
    "\n",
    "# Scanning angles in radian\n",
    "v_angles_rad_micron = df_sonar_micron[\"angle_rad\"].to_numpy(copy=True)\n",
    "v_angles_rad_seaking = df_sonar_seaking[\"angle_rad\"].to_numpy(copy=True)\n",
    "\n",
    "# Dimension adjustment\n",
    "v_angles_rad_micron_final = v_angles_rad_micron[d_ind_min_micron:d_ind_max_micron].copy()\n",
    "v_angles_rad_seaking_final = v_angles_rad_seaking[d_ind_min_seaking:d_ind_max_seaking].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "385a86c5-6e5f-46bb-a057-8e6e8c7a9afe",
   "metadata": {},
   "source": [
    "## Correction of the Vertical Sonar Orientation\n",
    "\n",
    "Correction to the orientation data of the vertical sonar (SeaKing):  \n",
    "\n",
    "1. Adjusts the Yaw-Pitch-Roll (YPR) data for the SeaKing sonar  \n",
    "2. Adds a rotation of π radians (180 degrees) to the pitch angle  \n",
    "\n",
    "::: {.callout-important}\n",
    "#### Explanation\n",
    "- The vertical sonar's actual orientation differs from the initially assumed configuration on the AUV  \n",
    "- This correction rotates the sonar's orientation by 180 degrees around the pitch axis  \n",
    "- The adjustment ensures accurate interpretation of the vertical sonar data in subsequent processing steps\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "This correction is neccessary for properly aligning the vertical sonar data with the AUV's frame of reference and the seafloor topography.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2878674-bfa8-4fcc-b87a-1ecbe225c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_interp_seaking_YPR = m_interp_seaking_YPR+np.array([0,np.pi,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7e56e01-a024-49b7-a354-b93e4deef042",
   "metadata": {},
   "source": [
    "## Beam Sonar data from 0-255 integers into 0-80 dB\n",
    "The received energy of the Horizontal Micron sonar is from 0 to 80 dB over 8 bits (0 for 0 dB and 255 for 80 dB).\n",
    "See more information on page 24 of the Micron product manual [here](https://www.tritech.co.uk/files/Manuals/Hardware-Manuals/0650-SOM-00003-04a-Micron-Sonar-Manual.pdf) and on page 25 Seaking product manual [here](https://www.tritech.co.uk/files/Manuals/Hardware-Manuals/0374-SOM-00001-08a-SeaKing-and-SeaPrince-Manual.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba8456-06c8-43c2-a016-ea46547fac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_beam_data_micron_final_in_dB = m_beam_data_micron_final/255*80\n",
    "m_beam_data_seaking_final_in_dB = m_beam_data_seaking_final/255*80"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce832701-ad75-4682-a9d1-7611eae282f2",
   "metadata": {},
   "source": [
    "## Add cleaned data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33ea694d-672b-4e72-bba4-e8841d4e496a",
   "metadata": {},
   "source": [
    "### Cleaning the horizontal sonar\n",
    "1. Creates a copy of the original data for cleaning  \n",
    "2. Removes constant noise lines (tranducer ringing noise) from the front and back of the AUV detection range  \n",
    "3. Applies a mask to remove background noise in specific regions  \n",
    "4. Implements a periodic cleaning process to address cyclic noise patterns  \n",
    "5. Applies hysteresis thresholding for further noise reduction  \n",
    "\n",
    "Key operations:  \n",
    "- Removes constant noise in the first 9 rows  \n",
    "- Uses a 200-step loop to clean periodic noise patterns  \n",
    "- Applies custom hysteresis thresholding function `f_hyster`  \n",
    "\n",
    "Outputs:  \n",
    "- `m_beam_data_micron_clean_hyst`: Cleaned horizontal sonar data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfc8b9-be55-4d17-ba85-d726209f3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_beam_data_micron_clean = m_beam_data_micron_final_in_dB.copy()\n",
    "\n",
    "# Selected part where the walls are far from the front and back AUV detection\n",
    "m_mask_instensity_back = m_beam_data_micron_final_in_dB[0:70, 594 - 35 : 594 + 35].copy()\n",
    "d_length_back_beam = 70\n",
    "d_length_back_start = -35\n",
    "d_length_back_end = 35\n",
    "\n",
    "m_mask_intensity_front = m_beam_data_micron_final_in_dB[0:30, 4064:4134]\n",
    "d_length_front_start = -35\n",
    "d_length_front_end = 35\n",
    "d_length_front_beam = 30\n",
    "\n",
    "# remove the constant line\n",
    "m_beam_data_micron_clean[0:9, :] = 0\n",
    "\n",
    "# First-period index\n",
    "d_first_period = 194  # Angle = 0°\n",
    "d_first_half_period = 94\n",
    "\n",
    "# Loop to remove the noise\n",
    "for d_ind in range(d_first_period, np.shape(m_beam_data_micron_clean)[1], 200):\n",
    "    m_aux = m_beam_data_micron_clean[0:d_length_back_beam, d_ind + d_length_back_start : d_ind + d_length_back_end].copy()\n",
    "    m_aux -= m_mask_instensity_back\n",
    "    m_aux[m_aux <= 0] = 0\n",
    "    m_beam_data_micron_clean[0:d_length_back_beam, d_ind + d_length_back_start : d_ind + d_length_back_end] = m_aux.copy()\n",
    "\n",
    "    m_aux_front = m_beam_data_micron_clean[0:d_length_front_beam, d_ind - 100 + d_length_front_start : d_ind - 100 + d_length_front_end].copy()\n",
    "    m_aux_front -= m_mask_intensity_front\n",
    "    m_aux_front[m_aux_front <= 0] = 0\n",
    "    m_beam_data_micron_clean[0:d_length_front_beam, d_ind - 100 + d_length_front_start : d_ind - 100 + d_length_front_end] = m_aux_front\n",
    "\n",
    "# Apply the hysteresis thresholding\n",
    "m_beam_data_micron_clean_hyst = f_hyster(m_beam_data_micron_clean, 0.4, 0.9, d_overlap=0.5, d_window_size=100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50f58ba2-c061-4d5c-925d-6b1bb4c99826",
   "metadata": {},
   "source": [
    "### Cleaning the vertical sonar\n",
    "1. Creates a copy of the original data  \n",
    "2. Removes noise lines from the first two rows  \n",
    "3. Applies hysteresis thresholding for noise reduction  \n",
    "\n",
    "Output:  \n",
    "- `m_beam_data_seaking_clean_hyst`: Cleaned vertical sonar data  \n",
    "\n",
    "::: {.callout-note}\n",
    "The horizontal sonar's cleaning process is more extensive due to its more complex noise patterns. The hysteresis thresholding parameters are adjusted differently for each sonar type to optimize noise reduction while preserving important features.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51c82d-9c41-4467-9734-0f9a11f95c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_beam_data_seaking_clean = m_beam_data_seaking_final_in_dB.copy()\n",
    "\n",
    "# Remove the line\n",
    "m_beam_data_seaking_clean[0:2, :] = 0\n",
    "\n",
    "# Apply the hysteresis thresholding\n",
    "m_beam_data_seaking_clean_hyst = f_hyster(m_beam_data_seaking_clean, 0.3, 0.9, d_overlap=0.5, d_window_size=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a664372-f68c-407e-a964-83f9da3207c6",
   "metadata": {},
   "source": [
    "## Processing Depth Sensor Data\n",
    "\n",
    "Handles the depth sensor data, which measures the AUV's depth in the water column. The process includes:\n",
    "\n",
    "1. Loading depth sensor data from a CSV file  \n",
    "2. Extracting the depth measurements into a NumPy array  \n",
    "3. Visualizing the depth profile  \n",
    "\n",
    "Key points:  \n",
    "- The depth values are negated in the plot to show increasing depth downwards, which is the conventional representation in oceanography  \n",
    "- This data complements the DVL-derived depth estimates and provides a more accurate depth profile of the AUV's trajectory  \n",
    "\n",
    "Comparing this direct depth measurement with the DVL-derived depth estimate can help validate the data and provide a more comprehensive understanding of the AUV's vertical movement during the mission.\n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "There is no information on the exact depth sensor position. We don't know about the potential offset.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a71c6-08ce-4f1a-8eab-afa63dd65668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357ebc0-1931-49fc-8947-3d10803c7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load depth sensor data\n",
    "df_depth = pd.read_csv(os.path.join(s_data_folder_path, 'depth_sensor.csv'))\n",
    "v_depth = df_depth['depth'].to_numpy(copy=True)\n",
    "v_timestamp_depth = df_depth['Time'].to_numpy(copy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46b0a4cd-95b8-41c3-a9f7-a859fdd1674a",
   "metadata": {},
   "source": [
    "## Processing Doppler Velocity Log (DVL) Data\n",
    "\n",
    "Processes data from the Doppler Velocity Log (DVL) sensor, which provides information about the AUV's velocity and altitude relative to the seafloor. The processing includes:  \n",
    "\n",
    "1. Loading DVL data from a CSV file  \n",
    "2. Extracting timestamps and altitude measurements  \n",
    "3. Cleaning and interpolating altitude data to remove invalid measurements  \n",
    "4. Processing velocity data in X, Y, and Z directions  \n",
    "5. Interpolating missing velocity values  \n",
    "6. Visualizing the processed data for verification  \n",
    "\n",
    "Key operations:  \n",
    "- Linear interpolation to replace invalid altitude measurements  \n",
    "- Handling of edge cases in velocity data where all components are zero  \n",
    "- Cumulative sum of Z-velocity to estimate depth profile  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0d5ce-48d2-473a-befd-9b46a297a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Doppler velocity sensor data\n",
    "\n",
    "# Load DVL data\n",
    "df_dvl = pd.read_csv(os.path.join(s_data_folder_path, 'dvl_linkquest.csv'))\n",
    "v_timestamp_dvl = df_dvl['Time'].to_numpy(copy=True)\n",
    "v_altitude_dvl = df_dvl['altitude'].to_numpy(copy=True)\n",
    "\n",
    "# # Visualize raw altitude data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(v_altitude_dvl)\n",
    "# plt.title(\"Raw Altitude Data from DVL\")\n",
    "# plt.xlabel(\"Sample Index\")\n",
    "# plt.ylabel(\"Altitude (m)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# Clean and interpolate altitude data\n",
    "indices_to_replace = np.where(v_altitude_dvl < 0)[0]\n",
    "for i in indices_to_replace:\n",
    "    if i == 0:\n",
    "        v_altitude_dvl[i] = v_altitude_dvl[i+1]\n",
    "    elif i == len(v_altitude_dvl) - 1:\n",
    "        v_altitude_dvl[i] = v_altitude_dvl[i-1]\n",
    "    else:\n",
    "        v_altitude_dvl[i] = (v_altitude_dvl[i-1] + v_altitude_dvl[i+1]) / 2\n",
    "\n",
    "# # Visualize cleaned altitude data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(v_altitude_dvl)\n",
    "# plt.title(\"Cleaned Altitude Data from DVL\")\n",
    "# plt.xlabel(\"Sample Index\")\n",
    "# plt.ylabel(\"Altitude (m)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# Process velocity data\n",
    "m_xyz_velocity_dvl = df_dvl[['velocityInst_0', 'velocityInst_1', 'velocityInst_2']].to_numpy(copy=True)\n",
    "\n",
    "# Interpolate missing velocity values\n",
    "zero_velocity_indices = np.where((m_xyz_velocity_dvl == 0).all(axis=1))[0]\n",
    "for index in zero_velocity_indices:\n",
    "    if index == 0:\n",
    "        m_xyz_velocity_dvl[index] = m_xyz_velocity_dvl[index+1]\n",
    "    elif index == len(m_xyz_velocity_dvl) - 1:\n",
    "        m_xyz_velocity_dvl[index] = m_xyz_velocity_dvl[index-1]\n",
    "    else:\n",
    "        m_xyz_velocity_dvl[index] = (m_xyz_velocity_dvl[index-1] + m_xyz_velocity_dvl[index+1]) / 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706276e9-87cc-41de-9ded-368c25ef1805",
   "metadata": {},
   "source": [
    "After interpolation we have:  \n",
    "**Horizontal Micron Sonar Data**  \n",
    "\n",
    "- `v_timestamp_sonar_micron_final`: Timestamps\n",
    "- `m_beam_data_micron_final_in_dB`: (397x45587) Received energy\n",
    "  per range and time\n",
    "- `m_interp_micron_YPR`: (45587x3) Yaw, Pitch, Roll over time\n",
    "- `m_interp_pos_micron_final`: (45587x3) 3D Cartesian position over time\n",
    "- `v_angles_rad_micron_final`: (45587x1) Scanning angle in radian over time starting at Xº (first 0º at index 194)\n",
    "- `v_range_micron`: (397x1) Range values (397 bins from 0 to 20 meters)\n",
    "- `v_offset_ypr_micron`: (3x1) Offset position from AUV reference\n",
    "\n",
    "**Vertical Seaking Sonar Data**  \n",
    "\n",
    "- `v_timestamp_sonar_seaking_final`: Timestamps\n",
    "- `m_beam_data_seaking_final_in_dB`: (50x97477) Received energy\n",
    "  per range and time\n",
    "- `m_interp_micron_YPR`: (97477x3) Yaw, Pitch, Roll over time\n",
    "- `m_interp_pos_micron_final`: (97477x3) 3D Cartesian position over time\n",
    "- `v_angles_rad_micron_final`: (97477x1) Scanning angle over time\n",
    "  (radians)\n",
    "- `v_range_micron`: (50x1) Range values (50 bins from 0 to 20 meters)\n",
    "- `v_offset_ypr_seaking`: (3x1) Offset position from AUV reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c1102-56e5-41b4-8854-a4233517bcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "affc3517-ad61-45a1-97d9-0605e24ccc4f",
   "metadata": {},
   "source": [
    "## Renaming and Saving of Processed AUV and Sonar Data\n",
    "Save each variable separately to allow to read one variable per file instead of the full dataset to optimize future RAM usage.\n",
    "\n",
    "Useful variables are renamed for improved readability and conciseness.  \n",
    "\n",
    "Function Used:  \n",
    "   - `f_save_var`: A custom function designed to save variables individually.  \n",
    "   - The function creates separate files for each variable\n",
    "\n",
    "Save Location:  \n",
    "   - Data is saved to the `../data/Pickle_dataset` directory.  \n",
    "   - Each variable is created inside this directory.  \n",
    "\n",
    "Saving data:  \n",
    "   - AUV position and orientation data (e.g., `m_ypr_micron`, `m_xyz_pos`)  \n",
    "   - Sonar intensity data, both raw and processed (e.g., `m_beam_data_micron`, `m_beam_data_micron_clean`)  \n",
    "   - Configuration data (e.g., `v_angles_rad_micron`, `v_range_micron`)  \n",
    "   - Timestamp information (e.g., `v_timestamp`, `v_timestamp_micron`)  \n",
    "   - Other relevant parameters and paths  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82210a3-ce0f-4585-b415-4ad96f24dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUV navigation data\n",
    "# m_xyz_pos = m_xyz_pos # unchanged\n",
    "# m_ypr = m_ypr  # unchanged\n",
    "# v_timestamp = v_timestamp # unchanged\n",
    "\n",
    "# Depth sensor\n",
    "# v_timestamp_depth = v_timestamp_depth  # unchanged\n",
    "# v_depth = v_depth  # unchanged\n",
    "\n",
    "# DVL sensor\n",
    "# v_timestamp_dvl = v_timestamp_dvl  # unchanged\n",
    "# v_altitude_dvl = v_altitude_dvl # unchanged\n",
    "# m_xyz_velocity_dvl = m_xyz_velocity_dvl # unchanged\n",
    " \n",
    "# Horizontal Micron Sonar Data\n",
    "v_timestamp_micron = v_timestamp_sonar_micron_final\n",
    "m_beam_data_micron = m_beam_data_micron_final_in_dB\n",
    "m_ypr_micron = m_interp_micron_YPR\n",
    "# m_xyz_pos_micron = m_xyz_pos_micron # unchanged\n",
    "v_angles_rad_micron = v_angles_rad_micron_final\n",
    "v_offset_xyz_pos_micron = v_offset_pos_micron\n",
    "m_beam_data_micron_clean = m_beam_data_micron_clean\n",
    "m_beam_data_micron_clean_hyst = m_beam_data_micron_clean_hyst\n",
    "\n",
    "# v_range_micron = v_range_micron  # unchanged\n",
    "# v_offset_ypr_micron = v_offset_ypr_micron  # unchanged\n",
    "\n",
    "# Vertical Seaking Sonar Data\n",
    "v_timestamp_seaking = v_timestamp_sonar_seaking_final\n",
    "m_beam_data_seaking = m_beam_data_seaking_final_in_dB\n",
    "m_ypr_seaking = m_interp_seaking_YPR\n",
    "# m_xyz_pos_seaking = m_xyz_pos_seaking # unchanged\n",
    "v_angles_rad_seaking = v_angles_rad_seaking_final\n",
    "# v_range_seaking = v_range_seaking  # unchanged\n",
    "# v_offset_ypr_seaking = v_offset_ypr_seaking  # unchanged\n",
    "v_offset_xyz_pos_seaking = v_offset_pos_seaking\n",
    "m_beam_data_seaking_clean = m_beam_data_seaking_clean\n",
    "m_beam_data_seaking_clean_hyst = m_beam_data_seaking_clean_hyst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a27778-307d-4512-a78a-3536df5cdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('.','data','Pickle_dataset')):\n",
    "    \n",
    "    # Save each variable in a corresponding file\n",
    "    f_save_var(os.path.join('.','data','Pickle_dataset'), globals(), \n",
    "     'm_ypr_micron',\n",
    "     'm_xyz_pos_micron',\n",
    "     'm_xyz_pos_seaking',\n",
    "     'm_ypr_seaking',\n",
    "     'm_xyz_pos',\n",
    "     'm_ypr',\n",
    "     'm_beam_data_micron',\n",
    "     'm_beam_data_seaking',\n",
    "     'm_beam_data_micron_clean',\n",
    "     'm_beam_data_micron_clean_hyst',\n",
    "     'm_beam_data_seaking_clean',\n",
    "     'm_beam_data_seaking_clean_hyst',\n",
    "     'v_angles_rad_micron',\n",
    "     'v_angles_rad_seaking',\n",
    "     'v_offset_xyz_pos_micron',\n",
    "     'v_offset_xyz_pos_seaking',\n",
    "     'v_offset_ypr_micron',\n",
    "     'v_offset_ypr_seaking',\n",
    "     'v_range_micron',\n",
    "     'v_range_seaking',\n",
    "     'v_timestamp',\n",
    "     'v_timestamp_micron',\n",
    "     'v_timestamp_seaking',\n",
    "     'v_timestamp_dvl',\n",
    "     'v_altitude_dvl',\n",
    "     'm_xyz_velocity_dvl',\n",
    "     'v_timestamp_depth',\n",
    "     'v_depth')\n",
    "else:\n",
    "    print('No dataset created as Pickle_dataset already exist...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f252de-cdf8-4228-8a43-66343cc79d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b88d9b-67b5-4812-84c1-dc67309a3f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e81d4-3ccd-44a6-9a32-f1896cf93274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
